{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes in y_true: (array([0, 1]), array([600, 209]))\n",
      "Label:  Action Threshold:  0.0289855072463768\n",
      "[0 1 0 0 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 1 0 0 1 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 1 1\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0\n",
      " 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 1 1 1 1 0 1\n",
      " 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 1 1 0 0\n",
      " 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 1 0 1 1 0 0 0 1 0 0 0 0\n",
      " 1 1 1 1 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 1\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1\n",
      " 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1\n",
      " 1 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 1 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 1 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0\n",
      " 0 1 1 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1] [1 1 0 1 1 0 1 0 1 1 1 0 1 0 1 0 1 1 0 0 1 1 0 1 0 1 1 0 0 0 1 0 1 1 1 1 1\n",
      " 1 0 1 1 1 1 0 1 1 0 1 0 0 1 0 1 1 1 0 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0\n",
      " 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 1 1 1 1 1 0 0 0 1 0 0\n",
      " 1 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 0 1 1 1 1\n",
      " 1 1 0 1 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 1 1 0 1\n",
      " 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0\n",
      " 1 0 0 0 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 1 0 1 1 1\n",
      " 0 1 0 0 0 0 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 0 0 0 1 1 1 1 0 0\n",
      " 1 1 1 1 1 1 0 1 0 1 0 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1\n",
      " 1 0 1 1 1 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 1 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1\n",
      " 0 1 1 0 0 1 1 0 0 1 1 0 1 1 1 0 0 1 0 1 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 1\n",
      " 1 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 1 1 1 0 1 1 0 1 1 1\n",
      " 1 1 1 0 1 1 1 1 0 1 1 1 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 0 1 0 1 0 0 1 1 1 1\n",
      " 0 1 1 0 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 0\n",
      " 0 1 1 1 0 1 0 1 0 0 1 0 1 0 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0\n",
      " 0 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1\n",
      " 1 1 1 1 0 1 1 0 1 0 0 0 1 1 0 0 1 1 0 1 1 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 0\n",
      " 0 1 0 1 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Action       0.27      0.67      0.39       209\n",
      "        None       0.77      0.38      0.51       600\n",
      "\n",
      "    accuracy                           0.45       809\n",
      "   macro avg       0.52      0.52      0.45       809\n",
      "weighted avg       0.64      0.45      0.48       809\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[140  69]\n",
      " [372 228]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    "\n",
    "labels = [\"Action\", \"Non-action\"]\n",
    "\n",
    "# Open test data and clean annotations\n",
    "data = pd.read_csv(\"../data/test_set.csv\")\n",
    "\n",
    "data[\"simplified_label\"] = [\"None\" if x==\"None\" else \"Action\" for x in data[\"SimplifiedLabel\"]]\n",
    "\n",
    "test_data = data.copy()\n",
    "\n",
    "test_data[\"clust_annotation\"] = test_data[\"simplified_label\"]\n",
    "\n",
    "test_data = test_data.sort_values(by=\"CommentID\")\n",
    "\n",
    "test_data_idx = list(test_data[\"CommentID\"].values)\n",
    "\n",
    "test_pred = pd.read_csv(f\"../data/predictions/predictions_dictionary_based.csv\")\n",
    "test_pred = test_pred[test_pred[\"CommentID\"].isin(test_data_idx)]\n",
    "test_pred = test_pred.sort_values(by=\"CommentID\")\n",
    "\n",
    "# Compute ROC-AUC, F1, Precision, Recall overall\n",
    "list_scores = []\n",
    "for label in labels:\n",
    "    if label!=\"Action\":\n",
    "        continue\n",
    "    y_true = (test_data[\"clust_annotation\"] == label)*1\n",
    "    y_true = np.array(y_true.values)\n",
    "\n",
    "    y_pred = np.array(test_pred[\"perc_action_words\"].values)\n",
    "    print(f\"Unique classes in y_true: {np.unique(y_true, return_counts=True)}\")\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    # get threshold on the top-right corner\n",
    "    idx = np.argmax(tpr - fpr)\n",
    "    threshold = thresholds[idx]\n",
    "    print(\"Label: \", label, \"Threshold: \", threshold)\n",
    "    y_pred = (y_pred > threshold)*1\n",
    "\n",
    "    print(y_true, y_pred)\n",
    "\n",
    "    # Generate classification report\n",
    "    class_report = classification_report(y_true=y_true, y_pred=y_pred, target_names=[\"Action\", \"None\"], labels=[1, 0])\n",
    "    print('\\nClassification Report:', flush=True)\n",
    "    print(class_report, flush=True)\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=[1,0])\n",
    "    print('\\nConfusion Matrix:', flush=True)\n",
    "    print(conf_matrix, flush=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
